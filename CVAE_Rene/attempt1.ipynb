{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02669811248779297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9912422,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928e4dfca5d44d8b960d99a86fb985ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02144598960876465,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 28881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cdfb0c7fa84031a180e2070feb66d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023074865341186523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1648877,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777f822e48a14a9bb0b5045d8c94fd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023302316665649414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4542,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750ed7b8f7154879975eb25ca406af91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_data = datasets.MNIST(root=\"../data\", train=True, \n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(root=\"../data\", train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y):\n",
    "\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=dim_x**2, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=dim_y),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        c_out = self.classifier(x)\n",
    "        return c_out # ,enc_cond_out\n",
    "\n",
    "model = CVAE(28, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022472143173217773,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7194de9b420b4bd981a097ca08f55634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.32259 | Test loss: 0.32020, Test acc: 21.33%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.31774 | Test loss: 0.31513, Test acc: 43.06%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.31260 | Test loss: 0.30966, Test acc: 54.02%\n",
      "\n",
      "Epoch: 3\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.30703 | Test loss: 0.30371, Test acc: 60.14%\n",
      "\n",
      "Epoch: 4\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.30094 | Test loss: 0.29720, Test acc: 63.92%\n",
      "\n",
      "Epoch: 5\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.29428 | Test loss: 0.29007, Test acc: 66.59%\n",
      "\n",
      "Epoch: 6\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.28697 | Test loss: 0.28228, Test acc: 68.14%\n",
      "\n",
      "Epoch: 7\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.27901 | Test loss: 0.27383, Test acc: 69.23%\n",
      "\n",
      "Epoch: 8\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.27041 | Test loss: 0.26477, Test acc: 69.96%\n",
      "\n",
      "Epoch: 9\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.26125 | Test loss: 0.25519, Test acc: 70.89%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 10\n",
    "\n",
    "# Create training and testing loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    # Add a loop to loop through training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train() \n",
    "        # 1. Forward pass\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y = torch.nn.functional.one_hot(y, 10).to(torch.float32)\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulatively add up the loss per epoch \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out how many samples have been seen\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    ### Testing\n",
    "    # Setup variables for accumulatively adding up loss and accuracy \n",
    "    test_loss, test_acc = 0, 0 \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)    \n",
    "            y = torch.nn.functional.one_hot(y, 10).to(torch.float32)\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "           \n",
    "            # 2. Calculate loss (accumatively)\n",
    "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
    "\n",
    "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
    "            test_acc += accuracy_fn(y_true=y.argmax(dim=1), y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
    "        # Divide total test loss by length of test dataloader (per batch)\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        # Divide total accuracy by length of test dataloader (per batch)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    ## Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inp = train_data[541][0]\n",
    "plt.imshow(inp.squeeze())\n",
    "out=torch.argmax(model(inp.to(device)), axis=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
