{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.distributions import Independent, Normal\n",
    "\n",
    "PRINT_REQ= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_data = datasets.MNIST(root=\"../data\", train=True, \n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(root=\"../data\", train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_debug(data):\n",
    "    if PRINT_REQ:\n",
    "        print(data)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=train_data.classes\n",
    "class_to_idx = train_data.class_to_idx\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y, dim_z):\n",
    "\n",
    "        super().__init__()\n",
    "         # Encoder layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1,padding='same')\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=2,padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1,padding='same')\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=2,padding=0)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=80, kernel_size=7, stride=1,padding='valid')\n",
    "        self.lin1 = nn.Linear(in_features=90, out_features=20)\n",
    "        self.lin2 = nn.Linear(in_features=90, out_features=20)\n",
    "\n",
    "        # reparameterization\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = inputs[0].to(device)#.unsqueeze(dim=0)\n",
    "        y = inputs[1].to(device)\n",
    "        print(f\"img shape: {x.shape}, labels shape: {y.shape}\")\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        print_debug(x.shape)\n",
    "        # 32, 28, 28\n",
    "        x = F.pad(x, (0,3,0,3))\n",
    "        print_debug(x.shape)\n",
    "        # 32, 31, 31\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        print_debug(x.shape)\n",
    "        # 32, 14, 14\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        print_debug(x.shape)\n",
    "        # 64, 14, 14\n",
    "        x = F.pad(x, (0,3,0,3))\n",
    "        print_debug(x.shape)\n",
    "        # 64, 17, 17\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        print_debug(x.shape)\n",
    "        # 64, 7, 7\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        print_debug(x.shape)\n",
    "        # 80, 1, 1\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        print_debug(f\"After flatten shape: {x.shape}\")\n",
    "        # 80\n",
    "        print(x.shape, y.shape)\n",
    "        concat = torch.cat([x, y], dim=1)\n",
    "        print_debug(f\"After concatenation shape: {concat.shape}\")\n",
    "        # 90\n",
    "        # loc=torch.zeros(mu_logvar.shape)\n",
    "        # scale=torch.ones(mu_logvar.shape)\n",
    "        # diagn = Independent(Normal(loc, scale), 1)\n",
    "        mu = self.lin1(concat)\n",
    "        print_debug(f\"mu shape: {mu.shape}\")\n",
    "        # 20\n",
    "        logvar = self.lin2(concat)\n",
    "        print_debug(f\"logvar shape: {logvar.shape}\")\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        print_debug(f\"Returning shape {z.shape}\")\n",
    "        return  mu, logvar, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dim_y, dim_z):\n",
    "        super().__init__()\n",
    "        self.dim_z = dim_z\n",
    "        self.dim_y = dim_y\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=30, out_channels=64, kernel_size=7, stride=1, padding=0) # valid means no pad\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=5, stride=2, padding=2, output_padding=1) # pad operation added in forward\n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.deconv5 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=5, stride=2, padding=2, output_padding=1) # pad operation added in forward\n",
    "        self.deconv6 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=5, stride=1,padding='same')\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs[0].to(device)#.unsqueeze(dim=0)\n",
    "        y = inputs[1].to(device)\n",
    "        print_debug(f\"latent space shape: {x.shape}, labels shape: {y.shape}\")\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = torch.reshape(x, (-1, self.dim_z+self.dim_y, 1, 1))\n",
    "        print_debug(f\"After concatenation shape: {x.shape}\")\n",
    "        x = F.leaky_relu(self.deconv1(x))\n",
    "        print_debug(f\"ConvTrans1 output shape: {x.shape}\")\n",
    "        x = F.leaky_relu(self.deconv2(x))\n",
    "        print_debug(f\"ConvTrans2 output shape: {x.shape}\")\n",
    "        x = F.pad(x, (0,0,0,0))\n",
    "        x = F.leaky_relu(self.deconv3(x))\n",
    "        print_debug(f\"ConvTrans3 output shape: {x.shape}\")\n",
    "        x = F.leaky_relu(self.deconv4(x))\n",
    "        print_debug(f\"ConvTrans4 output shape: {x.shape}\")\n",
    "        # x = F.pad(x, (0,3,0,3))\n",
    "        x = F.leaky_relu(self.deconv5(x))\n",
    "        print_debug(f\"ConvTrans5 output shape: {x.shape}\")\n",
    "        x = F.leaky_relu(self.deconv6(x))\n",
    "        print_debug(f\"ConvTrans6 output shape: {x.shape}\")\n",
    "        x = torch.sigmoid(self.conv(x))\n",
    "        print_debug(f\"Conv output shape: {x.shape}\")\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        print_debug(f\"After flatten shape: {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y, dim_z):\n",
    "        super().__init__()\n",
    "\n",
    "        #Encoder \n",
    "        self.encoder = Encoder(dim_x=dim_x, dim_y=dim_y, dim_z=dim_z)\n",
    "\n",
    "        #Decoder\n",
    "        self.decoder = Decoder(dim_y=dim_y, dim_z=dim_z)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, y = inputs        \n",
    "        print_debug(f\"Inputs shape: {x.shape} and labels: {y.shape}\")\n",
    "        mu, logvar, z = self.encoder((x,y))\n",
    "        out = self.decoder((z, y))\n",
    "        print_debug(f\"decoder output shape is: {out.shape}\")\n",
    "        return mu, logvar, out\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CVAE(dim_x=(28, 28, 1), dim_y=10, dim_z=20).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 80]) torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# Testing the architecture by sending one batch of data through CVAE\n",
    "for i, (x, y) in enumerate(train_dataloader):\n",
    "    y = F.one_hot(y, 10)\n",
    "    model((x,y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "# Download helper functions\n",
    "import requests\n",
    "from pathlib import Path\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "    print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "    print(\"Download helper_functions.py\")\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "    with open(\"helper_functions.py\", \"wb\") as f:\n",
    "        f.write(request.content)\n",
    "\n",
    "import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step():\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    # Train step\n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        # print(f\"Batch: {batch+1}/{len(train_dataloader)}\")\n",
    "        X = x.to(device)\n",
    "        y = F.one_hot(y, 10).to(device)\n",
    "        model.train()\n",
    "        #Forward pass\n",
    "        mu, logvar, y_pred = model((X,y))\n",
    "\n",
    "\n",
    "        #Loss\n",
    "        loss = loss_function(recon_x=y_pred, x=X, mu=mu, log_var=logvar)\n",
    "        \n",
    "\n",
    "        #zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #backprop\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        #step\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch % 600 == 0:\n",
    "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #         epoch+1, batch * len(X), len(train_dataloader.dataset),\n",
    "        #         100. * batch / len(train_dataloader), loss.item() / len(X)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch+1, train_loss / len(train_dataloader.dataset)))\n",
    "\n",
    "def test_step():\n",
    "    #Test step\n",
    "    model.eval()\n",
    "    test_loss= 0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(test_dataloader):\n",
    "            # print(f\"batch {batch+1}/{len(test_dataloader)}\")\n",
    "            X = X.to(device)\n",
    "            y = F.one_hot(y, 10).to(device)\n",
    "            mu, logvar, ypred = model((X, y))\n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(ypred, X, mu, logvar).item()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "---------\n",
      "====> Epoch: 1 Average loss: 83.9061\n",
      "====> Test set loss: 297.1501\n",
      "Epoch: 2\n",
      "---------\n",
      "====> Epoch: 2 Average loss: 56.2639\n",
      "====> Test set loss: 336.9322\n",
      "Epoch: 3\n",
      "---------\n",
      "====> Epoch: 3 Average loss: 54.7321\n",
      "====> Test set loss: 354.8426\n",
      "Epoch: 4\n",
      "---------\n",
      "====> Epoch: 4 Average loss: 54.1912\n",
      "====> Test set loss: 331.6208\n",
      "Epoch: 5\n",
      "---------\n",
      "====> Epoch: 5 Average loss: 56.4100\n",
      "====> Test set loss: 389.7023\n",
      "End Training\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs=5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch+1}\\n---------\")\n",
    "    train_step()\n",
    "    test_step()\n",
    "print(\"End Training\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, class_size): \n",
    "    targets = torch.zeros(len(labels), class_size)\n",
    "    for i, label in enumerate(labels):\n",
    "        targets[i, label] = 1\n",
    "    return Variable(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28]) torch.Size([1, 10])\n",
      "img shape: torch.Size([1, 1, 28, 28]), labels shape: torch.Size([1, 10])\n",
      "torch.Size([1, 80]) torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "img=train_data[0][0].unsqueeze(dim=1)\n",
    "img.shape\n",
    "c = torch.eye(10).cuda()\n",
    "lbl = c[4].unsqueeze(dim=0)\n",
    "print(img.shape, lbl.shape)\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    _, _, recon=model((img, lbl))\n",
    "\n",
    "\n",
    "# lbl=one_hot(lbl, 10)\n",
    "# lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon=recon.reshape([1,1,28,28])\n",
    "recon=recon.cpu()\n",
    "recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0ec9067dc0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVzklEQVR4nO3dW4yd1XUH8P8617nbHoyHAcylCKlySWLoyGkV1FJFpYQXyAsKD5EjoToPQQ0SD0X0ITyiqCTioYpkCopTpUSREoQfUBPqRkJ5iRgcYww0ARw7tpmL7TGei8+c6+rDfNABZq918n3nJvb/J1kzPnv22fv7ZtZ8Z8769l6iqiCiz75cvydARL3BYCeKBIOdKBIMdqJIMNiJIlHo5WD5sVEtTE4G20dH183+LZVgmxptAJCTltkudncIwlkLa17t8Mb2eMduj93dbEyWZE/W82Lxzpk3bevnAfDnnjd+HkdzVbPvznwj2HbqTB0Xlppbjp4p2EXkHgBPA8gD+HdVfdL6+sLkJK599JFg+xf3/c4cb70Znu56s2j2HSvaJzDn/NCXcuET7I3t8cbOOT9YtVY+9diFnP1L0Bu7BfunOssvQu+8ZNFo2S9qvXm7582Z+7ZiJdj21xPvmX2/MbEYbNv3D2fCczKf1SAieQD/BuArAPYAeFBE9qR9PiLqrix/s+8D8K6qnlTVGoCfALivM9Miok7LEuzXAdj8muFs8tjHiMgBEZkVkdnm6lqG4Ygoi66/G6+qB1V1RlVn8mOj3R6OiAKyBPs5ALs3/f/65DEiGkBZgv1VALeKyM0iUgLwNQCHOzMtIuq01Kk3VW2IyMMAfoGN1Ntzqvqm3QmQZrj5SqNkdr9hdCnY1lL791YhZwwMYH59wmwvG/1rLfs07h6+ZLYvVMfN9rFCzWy/UA3/eXTjSPicAcCF2pjZPpyvm+1LtRGz3Tr2887Y3nF/UBu2xx4Jj32hao9dNnLZADBfsb9nt4xdMNv/YiT8InhP2X6BfKQyFGxbNjKCmfLsqvoSgJeyPAcR9QZvlyWKBIOdKBIMdqJIMNiJIsFgJ4oEg50oEtLL3WXHJnfr5+5+JNier9nLBpdvCGcKK7vs48hX7SWLzZKzzHTrJcJt9S1Uso3tUSOBWlhz1m1n3NGgWXbOu3XszqXGWx2rhfRjt5xVyc72B2gOZzhuAOvTRh7f+XGQevi55777NKp/PLPlF/DKThQJBjtRJBjsRJFgsBNFgsFOFAkGO1EkerqVtLQUhSvhnMbIqWWz/8q1xjbUZ+2xvVTL0CU731G5OpzuKF22n7vubNBTWrHbKzvtNM7QxfDcG/YKVJRW0h83AIyGNzMFADSNVajlS3Z+a23avhYN2at3UTdWsZY/sI+7ut0+7vJJe+zK1Xa75sKhV99mn5ficnhu1hJyXtmJIsFgJ4oEg50oEgx2okgw2IkiwWAnigSDnSgSPc2zowXk18OJQB2yp5Ovh3Oj61fZedHiqj216nbn956R+qxN2GNbuU8AqI85FUPtStaojxulrJ1lojWjLwAUV+18dN059pyxE3V1h7P99xWzGY0Rb+zw3L3jzq9nu//A2dncXJ7rfc/Me0bSrygmos8KBjtRJBjsRJFgsBNFgsFOFAkGO1EkGOxEkehtnh2AGOnL3IqTUEa4TK6XR2/l7XZvfXMzXCUXObuysJkHB4DicvqxATsfve6shffy6N56+PJS+nXh3jn3xi4433Pr3gtrDwAAaJbt5x5ZcNbiX2tfR6Vh3BsxZJeLbtXDP8xWjj5TsIvIKQArAJoAGqo6k+X5iKh7OnFl/ztVtSvPE1Hf8W92okhkDXYF8EsReU1EDmz1BSJyQERmRWS2Xl/LOBwRpZX1ZfydqnpORHYBeFlE/ldVX9n8Bap6EMBBABifuL53heWI6GMyXdlV9VzycRHACwD2dWJSRNR5qYNdREZFZPzDzwHcDeBEpyZGRJ2V5WX8FIAXROTD5/lPVf0vt5fxQr41YWwy7qhus9uHL9h/QdS2pV+T3nCmXahkHNtOu5p7lHt59KxjV7fb7Tmjvze2p1qy24vGnvhVZ2xr3gBwZcrp79x70SqG5yY1J0ffSnfeUge7qp4E8IW0/Ymot5h6I4oEg50oEgx2okgw2IkiwWAnikTPl7haW+zmL9q1i5vF8BLX8iV73GbJKcGboYSv19fbtrjslIv2tsm2xm8532F37El7bK/ks7VU1DtvlV32tchKrQH299wbuz5qH/fIor3EtXKVPff8evj56zvt59b1dNdoXtmJIsFgJ4oEg50oEgx2okgw2IkiwWAnigSDnSgSPc2zC4BcI5zfbOyaMPvna8aSRS8ffDl9Hh1wyv+6ZYudPLzTP19NnxPOOra3PNcrN20tka3ucI7bGbtZdsZuGd8zb4mr8bMGAGvTznXSLbscfv7cmr3vuVhpeGurdntKRPRZwWAnigSDnSgSDHaiSDDYiSLBYCeKBIOdKBI9zbMrgFYhnIAsXa44zzAabCk4laW8fLC3rrtVTN/XW4/urctW57tkrSl316M75aK99fBefyuX7t370Bh28vDr6bfJ9tbhe8c9fD7b9zxnlGxuDRv7lgOQhpGHN4bllZ0oEgx2okgw2IkiwWAnigSDnSgSDHaiSDDYiSLR833jrbW4zfEhs6+153zNKdlcXsq2LluN5saIPXauard7Y/tro8NteW9sZ0972FuYo2l/y8zSxd7e7Gov64bmnTy8NfZItpLNlZ12u7nmHEBjxCjZ3MxWyjrEvbKLyHMisigiJzY9NikiL4vIO8nHHV2ZHRF1TDsv438I4J5PPPYYgCOqeiuAI8n/iWiAucGuqq8AWPrEw/cBOJR8fgjA/Z2dFhF1Wto36KZUdS75fB7AVOgLReSAiMyKyGy97tzATkRdk/ndeFVVGNvcqepBVZ1R1ZliMbyQhYi6K22wL4jINAAkHxc7NyUi6oa0wX4YwP7k8/0AXuzMdIioW9w8u4g8D+AuADtF5CyA7wB4EsBPReQhAKcBPNDWaAKosZ49v7Tq9B8LNhXt0u5odbE+e8FZ091wcrru2M7+6oUr4f5eLttbi+/tp++tZ28MGTXSnfXslZ3dG7u0lu2+i5HFbOetsBZub2yznzstN9hV9cFA05c7PBci6iLeLksUCQY7USQY7ESRYLATRYLBThSJ3i5xVUCMks3NyXBqDbDL/za220N7W/96qRJrbC9N45ZcdpaZdrNkszt3Z7tmt2SzsStyzelbdNJjVmrN48274Bz3lSlnbCd71iobJZvX7WuwdU5ZspmIGOxEsWCwE0WCwU4UCQY7USQY7ESRYLATRaK3eXYBWkVjievKut0/ZyxxdXa88vLoQ85W043hcFtp2R675i0TzVi62MpH1yayLa+1jhvwy01b42ctm1yopC+b7C2vbTnbWI/MZ8vD5+pGyeYhu2RzrsaSzURkYLATRYLBThQJBjtRJBjsRJFgsBNFgsFOFIme5tlFgXw1XMvWLdls5BBrE/bYWbdMttYJWyWTgTZKNmcsXVwztuf2Sg/XnLX0VplswJ9bvpb+HgCPua4bdh7fu3fBW49e2WW3uyWbh4ySzY0+lWwmos8GBjtRJBjsRJFgsBNFgsFOFAkGO1EkGOxEkehpnl0FaJXCv1/Kf3TqLhslm0uX7a7WOnogWx6+uJpxPbrTv7bNWQ+fIZ/s7c3ujZ131pQ3rZLN3jmfdPZ2d8a2SmV75Z7dks3zdiK9ssu+jhYqRsnmHfZzq6S7Rru9ROQ5EVkUkRObHntCRM6JyLHk372pRieinmnnV8QPAdyzxePfV9W9yb+XOjstIuo0N9hV9RUASz2YCxF1UZY36B4WkePJy/wdoS8SkQMiMisis/Was1EcEXVN2mD/AYBbAOwFMAfgqdAXqupBVZ1R1ZliaTTlcESUVapgV9UFVW2qagvAMwD2dXZaRNRpqYJdRKY3/ferAE6EvpaIBoObZxeR5wHcBWCniJwF8B0Ad4nIXmys+j0F4JttjebUZ69PbbPnYqQfGyP20N7e7NUdzj7ftXBb1vrsDWc9u5cLt9bDe2u+vbELV7LVlrfOm7ee3RvbyuED9nn3vt/e2GvT9nXSW+ffKhr12St257T12d1gV9UHt3j4Wa8fEQ0W3i5LFAkGO1EkGOxEkWCwE0WCwU4UiZ6XbFZj2+PCkn07rUo4v5Z3qj17Sz295ZZWestNTznpLW+5ZdPeYdtcIuulmLzjbpbtsbMsU3VLVRtLVAG/XLRVstkrF+0ZWXDG3mnPvcmSzUTULQx2okgw2IkiwWAnigSDnSgSDHaiSDDYiSLR2zy7s8S1NTFsdhcjtVkft4cufWC3uyWbjV+L1r0DQBtlk73SxRnKJrtjZyhVDQDq/ASJMb533N4yUTOpDPvei6wlm2vOz5unOZyhZLM1N6ONV3aiSDDYiSLBYCeKBIOdKBIMdqJIMNiJIsFgJ4rEQK1nz12+YnZvFcIlmwtOZalW0W4vf5B+Xba3VXTLycN769mzlE32tlt2t9h2yibnaumP3Ttuby2+u0W3cezeWnhvi+3h8856du+8VcPtut1+brUu0VzPTkQMdqJIMNiJIsFgJ4oEg50oEgx2okgw2Iki0fP17GgZOeHJUbO7tTbbW89e9HLZztpqK5fdytt9xThmIHvJZzOX7q3Lzlg2uVVyjt0q0e3ksvPrznEXvX0EjLG9UtN1e+zKLmctvrcHQcFYz17zfp6sJw43uVd2EdktIr8SkbdE5E0R+Xby+KSIvCwi7yQfd3jPRUT9087L+AaAR1V1D4C/AvAtEdkD4DEAR1T1VgBHkv8T0YByg11V51T1aPL5CoC3AVwH4D4Ah5IvOwTg/i7NkYg64E96g05EbgJwO4DfAJhS1bmkaR7AVKDPARGZFZHZet25gZ2IuqbtYBeRMQA/A/CIqi5vblNVReCtAVU9qKozqjpTLNpvwBFR97QV7CJSxEag/1hVf548vCAi00n7NIDF7kyRiDrBTb2JiAB4FsDbqvq9TU2HAewH8GTy8cWsk8lfWDHbW/nwK4PCqv3c3pLFoYvp02NWyWQAqDjle4eWMpYuNsavXJ3xuJ3z5i0Ntsb3+nopSW+ZapZy0S0nMkbmrfwXsHadfR21tovWsv3caqXmjKZ28uxfAvB1AG+IyLHkscexEeQ/FZGHAJwG8EAbz0VEfeIGu6r+GuHfF1/u7HSIqFt4uyxRJBjsRJFgsBNFgsFOFAkGO1EkervE1dHabt9hl6+G2ypb3qz7/7x8cs1b8mgtl3TywWUnp+v197ZrtnLhXj7ZG9squQz4pa6tewC8+we8sb3+5Uvhsb3vd8FY0gwAV6bs66S3tXl1Mvz8uYpdq1qa6ZY088pOFAkGO1EkGOxEkWCwE0WCwU4UCQY7USQY7ESR6EPJ5vDvl/ySvSi9MTIRbCs669m9ErpjZ531ydPheY8s2jnZtWln7HPpxwbs8sHeevbR97ONPbLg5aPD43vHveqsCffOuzW2N2/v/oHROWfuu+2559fDz1+ftG8wyFXThS2v7ESRYLATRYLBThQJBjtRJBjsRJFgsBNFgsFOFIme5tlFgfx6M9je3GGvZx+dD/etjXv5YGcvbqfsspUTtta6A8DEafu5PROn7blb4xeMfC4At6Szlwv3jn38bPpjH3PuAfBKWVvn3dsXfnTeKxdt9/dKhFtr8UsL9uSKq+G+uXCI8MpOFAsGO1EkGOxEkWCwE0WCwU4UCQY7USQY7ESRaKc++24APwIwhY2s7EFVfVpEngDwjwDOJ1/6uKq+ZD6ZKnL1cO5UX3vT7J6f3hdsmzy5bPZdu3nMbJ+YnTPbV28Lb0w/dtzue3nmWrN922vO2J+7xmy3xl+5fdrsO/76gtm+8nl7Q/7xY/bcl/8yfOwTR+2+K1+wjzvL2NtfnTf7ru3ZZbZvf/19s/3i3+4228eMe0bmv2jvG2/t3SBGnr2dm2oaAB5V1aMiMg7gNRF5OWn7vqr+axvPQUR91k599jkAc8nnKyLyNoDruj0xIuqsP+lvdhG5CcDtAH6TPPSwiBwXkedEZEegzwERmRWR2XrdqYlDRF3TdrCLyBiAnwF4RFWXAfwAwC0A9mLjyv/UVv1U9aCqzqjqTLFo3/tORN3TVrCLSBEbgf5jVf05AKjqgqo2VbUF4BkA4XfPiKjv3GAXEQHwLIC3VfV7mx7f/DbvVwGc6Pz0iKhT2nk3/ksAvg7gDRE5ljz2OIAHRWQvNtJxpwB803ui6lWCd/aH1waW/unzZv+Hb/tFsO2O4T+YfY9WbjbbbyydN9tP1sKpmJtKF8y+i43wFtgAcE3hA7P9/fqWb4d8ZHfpYrDtVO1qu28x3BcAztSv6lr/m5xz7s39msJls32+sS3YdmvJTr1Z32/A/56vq70G9pp8eO63lepm36cu3hFse+Z/VoJt7bwb/2sAWy2gtXPqRDRQeAcdUSQY7ESRYLATRYLBThQJBjtRJBjsRJHobcnmlkAq4eV7rSX7dtoLfx5epnr4cjj3CAAVZ+/foys3mO3jhfVg29tr9jLSothbIr/asu8BGM7XzPbfrobn7o19tHmjM7ad8z2u15vt1vhHl7s7dl7C2zkfc77fuYzfs51lu4Z4HuHnf2/knNk3LV7ZiSLBYCeKBIOdKBIMdqJIMNiJIsFgJ4oEg50oEqLq1Ozt5GAi5wGc3vTQTgD2wuD+GdS5Deq8AM4trU7O7UZV3XIjgJ4G+6cGF5lV1Zm+TcAwqHMb1HkBnFtavZobX8YTRYLBThSJfgf7wT6PbxnUuQ3qvADOLa2ezK2vf7MTUe/0+8pORD3CYCeKRF+CXUTuEZHfici7IvJYP+YQIiKnROQNETkmIrN9nstzIrIoIic2PTYpIi+LyDvJR3tT+d7O7QkROZecu2Micm+f5rZbRH4lIm+JyJsi8u3k8b6eO2NePTlvPf+bXUTyAH4P4O8BnAXwKoAHVfWtnk4kQEROAZhR1b7fgCEifwNgFcCPVPW25LHvAlhS1SeTX5Q7VPWfB2RuTwBY7XcZ76Ra0fTmMuMA7gfwDfTx3BnzegA9OG/9uLLvA/Cuqp5U1RqAnwC4rw/zGHiq+gqApU88fB+AQ8nnh7Dxw9JzgbkNBFWdU9WjyecrAD4sM97Xc2fMqyf6EezXATiz6f9nMVj13hXAL0XkNRE50O/JbGFKVeeSz+cBTPVzMltwy3j30ifKjA/MuUtT/jwrvkH3aXeq6h0AvgLgW8nL1YGkG3+DDVLutK0y3r2yRZnxj/Tz3KUtf55VP4L9HIDdm/5/ffLYQFDVc8nHRQAvYPBKUS98WEE3+bjY5/l8ZJDKeG9VZhwDcO76Wf68H8H+KoBbReRmESkB+BqAw32Yx6eIyGjyxglEZBTA3Ri8UtSHAexPPt8P4MU+zuVjBqWMd6jMOPp87vpe/lxVe/4PwL3YeEf+PQD/0o85BOb1ZwBeT/692e+5AXgeGy/r6th4b+MhAFcBOALgHQD/DWBygOb2HwDeAHAcG4E13ae53YmNl+jHARxL/t3b73NnzKsn5423yxJFgm/QEUWCwU4UCQY7USQY7ESRYLATRYLBThQJBjtRJP4P0XuTOpiBp7AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(recon[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[4].unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0f074cb550>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOZ0lEQVR4nO3dbYxc5XnG8euKbezamMQbB9chLjjgFAg0Jl0ZEBZQoVCCKgGqArGiyKG0ThOchNaVoLQqtKKVWyVElFIkU1xMxUsgAeEPNAm1ECRqcFlcY2wIb8Y0NmaNWYENIX5Z3/2w42iBnWeXmTMv3vv/k1Yzc+45c24NXD5nznNmHkeEAIx/H+p0AwDag7ADSRB2IAnCDiRB2IEkJrZzY4d5ckzRtHZuEkjlV3pbe2OPR6o1FXbb50m6QdIESf8WEctLz5+iaTrV5zSzSQAFa2NN3VrDh/G2J0i6SdLnJZ0oaZHtExt9PQCt1cxn9gWSXoiIzRGxV9Ldki6opi0AVWsm7EdJ+sWwx1try97F9hLbfbb79mlPE5sD0IyWn42PiBUR0RsRvZM0udWbA1BHM2HfJmnOsMefqC0D0IWaCfvjkubZnmv7MElflLS6mrYAVK3hobeI2G97qaQfaWjobWVEbKqsMwCVamqcPSIelPRgRb0AaCEulwWSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJpmZxRffzxPJ/4gkfm9nS7T/7F8fUrQ1OPVBc9+hjdxTrU7/uYv3V6w+rW1vX+73iujsH3y7WT713WbF+3J8/Vqx3QlNht71F0m5Jg5L2R0RvFU0BqF4Ve/bfi4idFbwOgBbiMzuQRLNhD0k/tv2E7SUjPcH2Ett9tvv2aU+TmwPQqGYP4xdGxDbbR0p6yPbPI+LR4U+IiBWSVkjSEe6JJrcHoEFN7dkjYlvtdoek+yUtqKIpANVrOOy2p9mefvC+pHMlbayqMQDVauYwfpak+20ffJ07I+KHlXQ1zkw4YV6xHpMnFeuvnPWRYv2d0+qPCfd8uDxe/JPPlMebO+k/fzm9WP/HfzmvWF978p11ay/te6e47vL+zxXrH//JofeJtOGwR8RmSZ+psBcALcTQG5AEYQeSIOxAEoQdSIKwA0nwFdcKDJ792WL9+ttuKtY/Nan+VzHHs30xWKz/zY1fKdYnvl0e/jr93qV1a9O37S+uO3lneWhuat/aYr0bsWcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ6/A5GdfKdaf+NWcYv1Tk/qrbKdSy7afVqxvfqv8U9S3Hfv9urU3D5THyWf9838X66106H2BdXTs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCUe0b0TxCPfEqT6nbdvrFgOXnl6s7zqv/HPPEzYcXqw/+fUbP3BPB12383eK9cfPKo+jD77xZrEep9f/AeIt3yyuqrmLniw/Ae+zNtZoVwyMOJc1e3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9i4wYeZHi/XB1weK9ZfurD9WvunMlcV1F/zDN4r1I2/q3HfK8cE1Nc5ue6XtHbY3DlvWY/sh28/XbmdU2TCA6o3lMP42Se+d9f4qSWsiYp6kNbXHALrYqGGPiEclvfc48gJJq2r3V0m6sNq2AFSt0d+gmxUR22v3X5U0q94TbS+RtESSpmhqg5sD0Kymz8bH0Bm+umf5ImJFRPRGRO8kTW52cwAa1GjY+23PlqTa7Y7qWgLQCo2GfbWkxbX7iyU9UE07AFpl1M/stu+SdLakmba3SrpG0nJJ99i+TNLLki5uZZPj3eDO15taf9+uxud3//SXni7WX7t5QvkFDpTnWEf3GDXsEbGoTomrY4BDCJfLAkkQdiAJwg4kQdiBJAg7kARTNo8DJ1z5XN3apSeXB03+/eg1xfpZX7i8WJ/+vceKdXQP9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7ONAadrk1792QnHd/1v9TrF+1XW3F+t/efFFxXr874fr1ub8/c+K66qNP3OeAXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCKZuTG/ij04v1O675drE+d+KUhrf96duXFuvzbtlerO/fvKXhbY9XTU3ZDGB8IOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnR1GcMb9YP2L51mL9rk/+qOFtH//wHxfrv/239b/HL0mDz29ueNuHqqbG2W2vtL3D9sZhy661vc32+trf+VU2DKB6YzmMv03SeSMs/25EzK/9PVhtWwCqNmrYI+JRSQNt6AVACzVzgm6p7Q21w/wZ9Z5ke4ntPtt9+7Snic0BaEajYb9Z0rGS5kvaLuk79Z4YESsiojcieidpcoObA9CshsIeEf0RMRgRByTdImlBtW0BqFpDYbc9e9jDiyRtrPdcAN1h1HF223dJOlvSTEn9kq6pPZ4vKSRtkfTViCh/+ViMs49HE2YdWay/cslxdWtrr7yhuO6HRtkXfemlc4v1Nxe+XqyPR6Vx9lEniYiIRSMsvrXprgC0FZfLAkkQdiAJwg4kQdiBJAg7kARfcUXH3LO1PGXzVB9WrP8y9hbrf/CNK+q/9v1ri+seqvgpaQCEHciCsANJEHYgCcIOJEHYgSQIO5DEqN96Q24HFs4v1l/8QnnK5pPmb6lbG20cfTQ3DpxSrE99oK+p1x9v2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs49z7j2pWH/um+Wx7lvOWFWsnzml/J3yZuyJfcX6YwNzyy9wYNRfN0+FPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+yFg4tyji/UXL/143dq1l9xdXPcPD9/ZUE9VuLq/t1h/5IbTivUZq8q/O493G3XPbnuO7YdtP217k+1v1Zb32H7I9vO12xmtbxdAo8ZyGL9f0rKIOFHSaZIut32ipKskrYmIeZLW1B4D6FKjhj0itkfEutr93ZKekXSUpAskHbyWcpWkC1vUI4AKfKDP7LaPkXSKpLWSZkXEwYuPX5U0q846SyQtkaQpmtpwowCaM+az8bYPl/QDSVdExK7htRiaHXLEGSIjYkVE9EZE7yRNbqpZAI0bU9htT9JQ0O+IiPtqi/ttz67VZ0va0ZoWAVRh1MN425Z0q6RnIuL6YaXVkhZLWl67faAlHY4DE4/5rWL9zd+dXaxf8nc/LNb/9CP3FeuttGx7eXjsZ/9af3it57b/Ka474wBDa1Uay2f2MyR9WdJTttfXll2toZDfY/sySS9LurglHQKoxKhhj4ifShpxcndJ51TbDoBW4XJZIAnCDiRB2IEkCDuQBGEHkuArrmM0cfZv1q0NrJxWXPdrcx8p1hdN72+opyos3bawWF938/xifeb3NxbrPbsZK+8W7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+x7f7/8s8V7/2ygWL/6uAfr1s79jbcb6qkq/YPv1K2duXpZcd3j//rnxXrPG+Vx8gPFKroJe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSCLNOPuWC8v/rj138r0t2/ZNbxxbrN/wyLnFugfr/bjvkOOve6lubV7/2uK6g8UqxhP27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQhCOi/AR7jqTbJc2SFJJWRMQNtq+V9CeSXqs99eqIqP+lb0lHuCdONRO/Aq2yNtZoVwyMeGHGWC6q2S9pWUSssz1d0hO2H6rVvhsR366qUQCtM5b52bdL2l67v9v2M5KOanVjAKr1gT6z2z5G0imSDl6DudT2Btsrbc+os84S2322+/ZpT3PdAmjYmMNu+3BJP5B0RUTsknSzpGMlzdfQnv87I60XESsiojcieidpcvMdA2jImMJue5KGgn5HRNwnSRHRHxGDEXFA0i2SFrSuTQDNGjXsti3pVknPRMT1w5bPHva0iySVp/ME0FFjORt/hqQvS3rK9vrasqslLbI9X0PDcVskfbUF/QGoyFjOxv9U0kjjdsUxdQDdhSvogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSYz6U9KVbsx+TdLLwxbNlLSzbQ18MN3aW7f2JdFbo6rs7eiI+NhIhbaG/X0bt/siordjDRR0a2/d2pdEb41qV28cxgNJEHYgiU6HfUWHt1/Srb11a18SvTWqLb119DM7gPbp9J4dQJsQdiCJjoTd9nm2n7X9gu2rOtFDPba32H7K9nrbfR3uZaXtHbY3DlvWY/sh28/XbkecY69DvV1re1vtvVtv+/wO9TbH9sO2n7a9yfa3ass7+t4V+mrL+9b2z+y2J0h6TtLnJG2V9LikRRHxdFsbqcP2Fkm9EdHxCzBsnynpLUm3R8RJtWX/JGkgIpbX/qGcERFXdklv10p6q9PTeNdmK5o9fJpxSRdK+oo6+N4V+rpYbXjfOrFnXyDphYjYHBF7Jd0t6YIO9NH1IuJRSQPvWXyBpFW1+6s09D9L29XprStExPaIWFe7v1vSwWnGO/reFfpqi06E/ShJvxj2eKu6a773kPRj20/YXtLpZkYwKyK21+6/KmlWJ5sZwajTeLfTe6YZ75r3rpHpz5vFCbr3WxgRn5X0eUmX1w5Xu1IMfQbrprHTMU3j3S4jTDP+a5187xqd/rxZnQj7Nklzhj3+RG1ZV4iIbbXbHZLuV/dNRd1/cAbd2u2ODvfza900jfdI04yrC967Tk5/3omwPy5pnu25tg+T9EVJqzvQx/vYnlY7cSLb0ySdq+6binq1pMW1+4slPdDBXt6lW6bxrjfNuDr83nV8+vOIaPufpPM1dEb+RUl/1Yke6vT1SUlP1v42dbo3SXdp6LBun4bObVwm6aOS1kh6XtJ/Serpot7+Q9JTkjZoKFizO9TbQg0dom+QtL72d36n37tCX21537hcFkiCE3RAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMT/A65XcTMQuIbWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
