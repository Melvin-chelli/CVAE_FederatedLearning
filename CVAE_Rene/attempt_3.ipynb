{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa3799b4a50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.distributions import Independent, Normal\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure as ssim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "PRINT_REQ= False\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "BATCH_SIZE=256\n",
    "EPOCHS=150\n",
    "\n",
    "cond_shape=10\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size = 128\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_data = datasets.MNIST(root=\"../data\", train=True, \n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(root=\"../data\", train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last=True, num_workers=4)\n",
    "\n",
    "flat_img=torch.flatten(train_data[0][0])\n",
    "flat_shape=list(flat_img.shape)\n",
    "flat_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_debug(data):\n",
    "    if PRINT_REQ:\n",
    "        print(data)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y, dim_z):\n",
    "\n",
    "        super().__init__()\n",
    "         # Encoder layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=11, out_channels=32, kernel_size=5, stride=1,padding='same')\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=2,padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1,padding='same')\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=2,padding=0)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=80, kernel_size=7, stride=1,padding='valid')\n",
    "        self.lin1 = nn.Linear(in_features=80, out_features=20)\n",
    "        self.lin2 = nn.Linear(in_features=80, out_features=20)\n",
    "\n",
    "        # reparameterization\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = inputs[0].to(device)\n",
    "        y = inputs[1].to(device)\n",
    "        \n",
    "        # y = F.one_hot(y, 10).to(device)\n",
    "        y = y.view(-1, 10, 1, 1).to(device)\n",
    "        \n",
    "        ones = torch.ones(x.size()[0], \n",
    "                            10,\n",
    "                            x.size()[2], \n",
    "                            x.size()[3], \n",
    "                            dtype=x.dtype).to(device)\n",
    "        y = ones * y\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        \n",
    "        print_debug(f\"input shape: {x.shape}\")\n",
    "        x = F.relu(self.conv1(x))\n",
    "        print_debug(x.shape)\n",
    "        # 32, 28, 28\n",
    "        x = F.pad(x, (0,3,0,3))\n",
    "        print_debug(x.shape)\n",
    "        # 32, 31, 31\n",
    "        x = F.relu(self.conv2(x))\n",
    "        print_debug(x.shape)\n",
    "        # 32, 14, 14\n",
    "        x = F.relu(self.conv3(x))\n",
    "        print_debug(x.shape)\n",
    "        # 64, 14, 14\n",
    "        x = F.pad(x, (0,3,0,3))\n",
    "        print_debug(x.shape)\n",
    "        # 64, 17, 17\n",
    "        x = F.relu(self.conv4(x))\n",
    "        print_debug(x.shape)\n",
    "        # 64, 7, 7\n",
    "        x = F.relu(self.conv5(x))\n",
    "        print_debug(x.shape)\n",
    "        # 80, 1, 1\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        print_debug(f\"After flatten shape: {x.shape}\")\n",
    "        # 80\n",
    "        # print_debug(f\"Concatenating {x.shape} with {y.shape}\")\n",
    "        # concat = torch.cat([x, y], dim=-1)\n",
    "        # print_debug(f\"After concatenation shape: {concat.shape}\")\n",
    "        # 90\n",
    "        # loc=torch.zeros(mu_logvar.shape)\n",
    "        # scale=torch.ones(mu_logvar.shape)\n",
    "        # diagn = Independent(Normal(loc, scale), 1)\n",
    "        mu = self.lin1(x)\n",
    "        print_debug(f\"mu shape: {mu.shape}\")\n",
    "        # 20\n",
    "        logvar = self.lin2(x)\n",
    "        print_debug(f\"logvar shape: {logvar.shape}\")\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        print_debug(f\"Returning shape {z.shape}\")\n",
    "        return  mu, logvar, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dim_y, dim_z):\n",
    "        super().__init__()\n",
    "        self.dim_z = dim_z\n",
    "        self.dim_y = dim_y\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=30, out_channels=64, kernel_size=7, stride=1, padding=0) # valid means no pad\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=5, stride=2, padding=2, output_padding=1) # pad operation added in forward\n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.deconv5 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=5, stride=2, padding=2, output_padding=1) # pad operation added in forward\n",
    "        self.deconv6 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=5, stride=1,padding='same')\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs[0].to(device)#.unsqueeze(dim=0)\n",
    "        y = inputs[1].to(device)\n",
    "        print_debug(f\"latent space shape: {x.shape}, labels shape: {y.shape}\")\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = torch.reshape(x, (-1, self.dim_z+self.dim_y, 1, 1))\n",
    "        print_debug(f\"After concatenation shape: {x.shape}\")\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        print_debug(f\"ConvTrans1 output shape: {x.shape}\")\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        print_debug(f\"ConvTrans2 output shape: {x.shape}\")\n",
    "        x = F.pad(x, (0,0,0,0))\n",
    "        x = F.relu(self.deconv3(x))\n",
    "        print_debug(f\"ConvTrans3 output shape: {x.shape}\")\n",
    "        x = F.relu(self.deconv4(x))\n",
    "        print_debug(f\"ConvTrans4 output shape: {x.shape}\")\n",
    "        # x = F.pad(x, (0,3,0,3))\n",
    "        x = F.relu(self.deconv5(x))\n",
    "        print_debug(f\"ConvTrans5 output shape: {x.shape}\")\n",
    "        x = F.relu(self.deconv6(x))\n",
    "        print_debug(f\"ConvTrans6 output shape: {x.shape}\")\n",
    "        x = torch.sigmoid(self.conv(x))\n",
    "        print_debug(f\"Conv output shape: {x.shape}\")\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        print_debug(f\"After flatten shape: {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y, dim_z):\n",
    "        super().__init__()\n",
    "\n",
    "        #Encoder \n",
    "        self.encoder = Encoder(dim_x=dim_x, dim_y=dim_y, dim_z=dim_z)\n",
    "\n",
    "        #Decoder\n",
    "        self.decoder = Decoder(dim_y=dim_y, dim_z=dim_z)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, y = inputs      \n",
    "        y = F.one_hot(y, 10)  \n",
    "        print_debug(f\"Inputs shape: {x.shape} and labels: {y.shape}\")\n",
    "        mu, logvar, z = self.encoder((x,y))\n",
    "        out = self.decoder((z, y))\n",
    "        print_debug(f\"decoder output shape is: {out.shape}\")\n",
    "        return mu, logvar, out\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CVAE(dim_x=(28, 28, 1), dim_y=10, dim_z=20).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "def loss_fn(recon, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon, x, reduction='sum')        \n",
    "    KLD = -0.5*torch.sum(1+logvar-mu.pow(2)-logvar.exp())\n",
    "    return BCE+KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one iteration to validate output shapes with PRINT_DEBUG = True\n",
    "for i, (x, y) in enumerate(train_dataloader):    \n",
    "    model((x,y))\n",
    "    # x = x.to(device)\n",
    "    # print(f\"ysghape is {y.shape}\")\n",
    "    # y = F.one_hot(y, 10).to(device)\n",
    "    # y = y.view(-1, 10, 1, 1).to(device)\n",
    "    \n",
    "    # ones = torch.ones(x.size()[0], \n",
    "    #                     10,\n",
    "    #                     x.size()[2], \n",
    "    #                     x.size()[3], \n",
    "    #                     dtype=x.dtype).to(device)\n",
    "    # y = ones * y\n",
    "    # print(ones.shape, y.shape)\n",
    "    # x = torch.cat((x, y), dim=1)\n",
    "    # print(x.shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X = X.to(device) #[64, 1, 28, 28]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 1. Forward pass\n",
    "        mu, logvar, recon_batch = model((X, y))\n",
    "        \n",
    "        flat_data = X.view(-1, flat_shape[0]).to(device)                            \n",
    "        y_onehot = F.one_hot(y, cond_shape).to(device)\n",
    "        inp = torch.cat((flat_data, y_onehot), 1)\n",
    "        \n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(recon_batch, flat_data, mu, logvar)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 3. Zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Backprop\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Step\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch * len(X),\n",
    "                len(train_dataloader.dataset),\n",
    "                100. * batch / len(train_dataloader),\n",
    "                loss.item() / len(X)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    #Sets the module in evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for i, (X, y) in enumerate(test_dataloader):\n",
    "            X = X.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            mu, logvar, recon_batch = model((X, y))\n",
    "            \n",
    "            flat_data = X.view(-1, flat_shape[0]).to(device)\n",
    "            y_onehot = F.one_hot(y, cond_shape).to(device)\n",
    "            inp = torch.cat((flat_data, y_onehot), 1)\n",
    "\n",
    "            # 2. Loss\n",
    "            test_loss += loss_fn(recon_batch, flat_data, mu, logvar).item()\n",
    "\n",
    "            # 3. Save images\n",
    "            if epoch%5==0 and i == 0:\n",
    "                n = min(X.size(0), 8)\n",
    "                recon_image = recon_batch[:, 0:recon_batch.shape[1]]\n",
    "                print(recon_image.shape)\n",
    "                recon_image = recon_image.view(BATCH_SIZE, 1, 28,28)\n",
    "                print('---',recon_image.shape)\n",
    "                comparison = torch.cat([X[:n],\n",
    "                                      recon_image.view(BATCH_SIZE, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 551.363525\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 550.775208\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 550.253784\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 549.720764\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 549.110657\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 548.485718\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 547.808411\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 547.166931\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 546.336548\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 545.397705\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 544.320984\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 542.995422\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 541.324097\n",
      "Train Epoch: 1 [33280/60000 (56%)]\tLoss: 538.889404\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 535.524292\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 530.028931\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 521.470398\n",
      "Train Epoch: 1 [43520/60000 (73%)]\tLoss: 507.041779\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 480.145691\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 450.457001\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 430.252319\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 418.944336\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 419.784180\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 413.489471\n",
      "====> Epoch: 1 Average loss: 514.2223\n",
      "====> Test set loss: 416.7981\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 420.320343\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 407.931366\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 410.863464\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 411.296417\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 414.046570\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 410.939331\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 408.051331\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 403.398895\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 402.353729\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 397.295746\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 399.486938\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 393.086273\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 384.175323\n",
      "Train Epoch: 2 [33280/60000 (56%)]\tLoss: 387.650543\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 394.349518\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 395.148315\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 380.872375\n",
      "Train Epoch: 2 [43520/60000 (73%)]\tLoss: 377.649750\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 379.985443\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 371.213104\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 369.049774\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 365.444672\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 360.474976\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 354.796082\n",
      "====> Epoch: 2 Average loss: 391.1077\n",
      "====> Test set loss: 351.5037\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 351.746460\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 352.824738\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 329.044739\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 333.054901\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 330.736298\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 314.624207\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 306.442230\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 310.948517\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 302.985840\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 293.762787\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 292.027344\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 288.168823\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 291.060150\n",
      "Train Epoch: 3 [33280/60000 (56%)]\tLoss: 286.683197\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 277.127655\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 270.200287\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 272.877350\n",
      "Train Epoch: 3 [43520/60000 (73%)]\tLoss: 271.271698\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 261.535065\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 261.645203\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 259.622284\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 257.371338\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 250.448196\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 256.173645\n",
      "====> Epoch: 3 Average loss: 290.1646\n",
      "====> Test set loss: 248.0046\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 256.401123\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 243.707108\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 245.531036\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 236.708130\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 241.886932\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 232.325348\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 232.025574\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 231.676483\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 228.280273\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 228.376740\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 227.054214\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 221.997238\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 219.398041\n",
      "Train Epoch: 4 [33280/60000 (56%)]\tLoss: 222.568665\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 220.027542\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 218.793625\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 224.591095\n",
      "Train Epoch: 4 [43520/60000 (73%)]\tLoss: 218.151230\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 216.232361\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 218.324860\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 216.713669\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 216.858200\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 218.480957\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 213.280533\n",
      "====> Epoch: 4 Average loss: 225.9679\n",
      "====> Test set loss: 215.0297\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 218.309982\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 220.713531\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 213.883331\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 210.714859\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 214.534729\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 214.321060\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 210.908142\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 211.635269\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 210.828125\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 210.724670\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 214.577988\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 207.730865\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 212.099884\n",
      "Train Epoch: 5 [33280/60000 (56%)]\tLoss: 209.739838\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 209.965439\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 211.578293\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 203.521225\n",
      "Train Epoch: 5 [43520/60000 (73%)]\tLoss: 209.238480\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 207.473297\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 206.796539\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 206.874786\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 211.080780\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 204.191193\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 208.100693\n",
      "====> Epoch: 5 Average loss: 210.7869\n",
      "torch.Size([256, 784])\n",
      "--- torch.Size([256, 1, 28, 28])\n",
      "====> Test set loss: 207.3555\n",
      "Random number: 4\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 205.675919\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 206.605698\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 210.313080\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 199.165848\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 206.707764\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 209.755432\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 207.222626\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 205.411224\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 206.933167\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 205.166580\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 199.502472\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 207.252747\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 202.614731\n",
      "Train Epoch: 6 [33280/60000 (56%)]\tLoss: 202.013306\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 208.666580\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 205.329269\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 204.885971\n",
      "Train Epoch: 6 [43520/60000 (73%)]\tLoss: 200.408600\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 198.871109\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 198.830627\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 208.742310\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 202.808167\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 199.745407\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 199.721893\n",
      "====> Epoch: 6 Average loss: 204.6274\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "    # Generate random digits every n epochs\n",
    "    with torch.inference_mode():\n",
    "        if epoch%5==0:\n",
    "            sample = torch.randn(64, 20).to(device)\n",
    "        \n",
    "            c = np.zeros(shape=(sample.shape[0],))\n",
    "            rand = np.random.randint(0, 10)\n",
    "            print(f\"Random number: {rand}\")\n",
    "            c[:] = rand\n",
    "            c = torch.FloatTensor(c)\n",
    "            c = c.to(torch.int64)\n",
    "            c = c.to(device)\n",
    "            c = F.one_hot(c, cond_shape)\n",
    "            sample = model.decoder((sample, c)).cpu()\n",
    "            \n",
    "            generated_image = sample[:, 0:sample.shape[1]]\n",
    "            \n",
    "            \n",
    "            save_image(generated_image.view(64, 1, 28, 28),\n",
    "                    'results/sample_' + str(epoch) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    z = torch.randn(1, 20).cuda()\n",
    "    c = torch.eye(10).cuda()\n",
    "    lbl = c[0].unsqueeze(dim=0)\n",
    "    lbl = lbl.to(torch.int64)\n",
    "    print(lbl)\n",
    "    sample = model.decoder((z, lbl))\n",
    "sample=sample.cpu()\n",
    "sample=sample.reshape([1,1,28,28])\n",
    "plt.imshow(sample[0].squeeze().cpu(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
